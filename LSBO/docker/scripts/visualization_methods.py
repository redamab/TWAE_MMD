"""
High-Quality Visualization Methods for LSBO-Guided TWAE-MMD Training
IMPROVED VERSION: Shows AMP/non-AMP separation, Prior/Posterior matching, and Quality distribution
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from pathlib import Path
import tensorflow as tf


def create_training_visualizations(history, output_dir, epoch):
    """
    Create comprehensive high-resolution training visualizations.
    
    Args:
        history: Training history dictionary
        output_dir: Output directory for visualizations
        epoch: Current epoch number
    """
    # Set high-quality plot parameters
    plt.rcParams['figure.dpi'] = 300
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['figure.figsize'] = (20, 12)
    plt.rcParams['font.size'] = 10
    plt.rcParams['axes.labelsize'] = 12
    plt.rcParams['axes.titlesize'] = 14
    plt.rcParams['xtick.labelsize'] = 10
    plt.rcParams['ytick.labelsize'] = 10
    plt.rcParams['legend.fontsize'] = 10
    
    # Set style
    sns.set_style("whitegrid")
    sns.set_palette("husl")
    
    # Create figure with subplots
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    epochs = history['epoch']
    
    # 1. Loss Curves (Top Left)
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)
    ax1.plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)
    ax1.set_xlabel('Epoch', fontweight='bold')
    ax1.set_ylabel('Loss', fontweight='bold')
    ax1.set_title('ðŸ“‰ Training & Validation Loss', fontsize=14, fontweight='bold')
    ax1.legend(loc='best', framealpha=0.9)
    ax1.grid(True, alpha=0.3)
    
    # 2. Accuracy Curves (Top Middle)
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.plot(epochs, history['train_accuracy'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)
    ax2.plot(epochs, history['val_accuracy'], 'orange', linewidth=2, label='Val Acc', marker='s', markersize=4)
    ax2.set_xlabel('Epoch', fontweight='bold')
    ax2.set_ylabel('Accuracy', fontweight='bold')
    ax2.set_title('ðŸ“ˆ Classification Accuracy', fontsize=14, fontweight='bold')
    ax2.legend(loc='best', framealpha=0.9)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0.5, 1.0])
    
    # 3. Reconstruction Loss (Top Right)
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.plot(epochs, history['reconstruction_loss'], 'purple', linewidth=2, label='Reconstruction Loss', marker='o', markersize=4)
    ax3.set_xlabel('Epoch', fontweight='bold')
    ax3.set_ylabel('Reconstruction Loss', fontweight='bold')
    ax3.set_title('ðŸ”„ Reconstruction Loss (Decoder Quality)', fontsize=14, fontweight='bold')
    ax3.legend(loc='best', framealpha=0.9)
    ax3.grid(True, alpha=0.3)
    
    # 4. MMD Loss (Middle Left)
    ax4 = fig.add_subplot(gs[1, 0])
    ax4.plot(epochs, history['mmd_loss'], 'teal', linewidth=2, label='MMD Loss', marker='o', markersize=4)
    ax4.set_xlabel('Epoch', fontweight='bold')
    ax4.set_ylabel('MMD Loss', fontweight='bold')
    ax4.set_title('ðŸŽ¯ MMD Loss (LSBO-Guided Prior)', fontsize=14, fontweight='bold')
    ax4.legend(loc='best', framealpha=0.9)
    ax4.grid(True, alpha=0.3)
    
    # 5. High-Quality Regions (Middle Middle)
    ax5 = fig.add_subplot(gs[1, 1])
    ax5.plot(epochs, history['high_quality_regions'], 'darkgreen', linewidth=2, label='HQ Regions', marker='o', markersize=4)
    ax5.axhline(y=1000, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Max Capacity')
    ax5.set_xlabel('Epoch', fontweight='bold')
    ax5.set_ylabel('Number of Regions', fontweight='bold')
    ax5.set_title('ðŸ—ºï¸ High-Quality Latent Regions Discovered', fontsize=14, fontweight='bold')
    ax5.legend(loc='best', framealpha=0.9)
    ax5.grid(True, alpha=0.3)
    
    # 6. Average Latent Score (Middle Right)
    ax6 = fig.add_subplot(gs[1, 2])
    ax6.plot(epochs, history['average_latent_score'], 'darkblue', linewidth=2, label='Avg Score', marker='o', markersize=4)
    ax6.axhline(y=0.80, color='green', linestyle='--', linewidth=1, alpha=0.5, label='Target (0.80)')
    ax6.set_xlabel('Epoch', fontweight='bold')
    ax6.set_ylabel('Quality Score', fontweight='bold')
    ax6.set_title('â­ Average Latent Region Quality', fontsize=14, fontweight='bold')
    ax6.legend(loc='best', framealpha=0.9)
    ax6.grid(True, alpha=0.3)
    ax6.set_ylim([0.5, 1.0])
    
    # 7. Epoch Time (Bottom Left)
    ax7 = fig.add_subplot(gs[2, 0])
    ax7.plot(epochs, history['epoch_time'], 'brown', linewidth=2, label='Epoch Time', marker='o', markersize=4)
    ax7.set_xlabel('Epoch', fontweight='bold')
    ax7.set_ylabel('Time (seconds)', fontweight='bold')
    ax7.set_title('â±ï¸ Training Speed', fontsize=14, fontweight='bold')
    ax7.legend(loc='best', framealpha=0.9)
    ax7.grid(True, alpha=0.3)
    
    # 8. Loss Components Breakdown (Bottom Middle)
    ax8 = fig.add_subplot(gs[2, 1])
    if len(epochs) > 0:
        last_epoch_idx = -1
        components = {
            'Classification': history['classification_loss'][last_epoch_idx],
            'Reconstruction': history['reconstruction_loss'][last_epoch_idx],
            'MMD': history['mmd_loss'][last_epoch_idx],
            'Wasserstein': history['wasserstein_loss'][last_epoch_idx]
        }
        colors = ['#3498db', '#e74c3c', '#9b59b6', '#1abc9c']
        ax8.bar(components.keys(), components.values(), color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax8.set_ylabel('Loss Value', fontweight='bold')
        ax8.set_title(f'ðŸ“Š Loss Components (Epoch {epoch})', fontsize=14, fontweight='bold')
        ax8.grid(True, alpha=0.3, axis='y')
        plt.setp(ax8.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # 9. LSBO Statistics Summary (Bottom Right)
    ax9 = fig.add_subplot(gs[2, 2])
    ax9.axis('off')
    
    if len(epochs) > 0:
        summary_text = f"""
        ðŸŽ¯ LSBO-Guided Training Summary
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        ðŸ“ˆ Current Epoch: {epoch}
        
        ðŸŽ“ Classification Performance:
           â€¢ Train Accuracy: {history['train_accuracy'][-1]:.4f}
           â€¢ Val Accuracy: {history['val_accuracy'][-1]:.4f}
        
        ðŸ§¬ Latent Space Quality:
           â€¢ MMD Loss: {history['mmd_loss'][-1]:.4f}
           â€¢ Wasserstein Loss: {history['wasserstein_loss'][-1]:.4f}
           â€¢ HQ Regions: {history['high_quality_regions'][-1]}
           â€¢ Avg Score: {history['average_latent_score'][-1]:.4f}
        
        âš¡ Training Efficiency:
           â€¢ Epoch Time: {history['epoch_time'][-1]:.2f}s
           â€¢ Total Time: {sum(history['epoch_time']):.2f}s
        
        âœ¨ Innovation: LSBO-guided sampling
           (No random Gaussian sampling!)
        """
        ax9.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',
                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    # Add main title
    fig.suptitle('ðŸš€ LSBO-Guided TWAE-MMD Training Dashboard', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    # Save figure
    output_path = Path(output_dir) / f'training_dashboard_epoch_{epoch:03d}.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return output_path


def visualize_latent_space(model, dataset, output_dir, epoch, num_samples=2000, lsbo_sampler=None):
    """
    Create IMPROVED latent space visualizations with 3 panels:
    1. AMP (red) vs non-AMP (blue) separation
    2. Prior (triangles) vs Posterior (circles) overlay
    3. Quality score distribution
    
    Args:
        model: Trained TWAE-MMD model
        dataset: Dataset to sample from
        output_dir: Output directory for visualizations
        epoch: Current epoch number
        num_samples: Number of samples to visualize
        lsbo_sampler: Optional LSBO sampler for prior visualization
    """
    print(f"  ðŸ“Š Creating improved latent space visualization...")
    
    # ===== 1. Collect POSTERIOR samples (encoded from real data) =====
    print(f"    Collecting posterior samples...")
    latent_vectors_posterior = []
    labels_posterior = []
    
    # ðŸ”§ FIX: Shuffle dataset before sampling to ensure balanced AMP/Non-AMP representation
    # Validation dataset has shuffle=False, so we need to shuffle here for visualization
    dataset_shuffled = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=False)
    
    for batch in dataset_shuffled.take(num_samples // 64 + 1):
        sequences = batch['input_ids']
        batch_labels = batch['labels']
        
        outputs = model(sequences, training=False)
        latent_vectors_posterior.append(outputs['latent_vector'].numpy())
        labels_posterior.append(batch_labels.numpy())
        
        if len(latent_vectors_posterior) * 64 >= num_samples:
            break
    
    latent_vectors_posterior = np.concatenate(latent_vectors_posterior, axis=0)[:num_samples]
    labels_posterior = np.concatenate(labels_posterior, axis=0)[:num_samples]
    
    # ===== 2. Collect PRIOR samples (from LSBO high-quality regions) =====
    print(f"    Collecting prior samples...")
    latent_vectors_prior = np.array([])
    
    if lsbo_sampler is not None and hasattr(lsbo_sampler, 'high_quality_regions'):
        if len(lsbo_sampler.high_quality_regions) > 0:
            # Sample from HQ regions
            num_prior_samples = min(500, len(lsbo_sampler.high_quality_regions))
            prior_samples = lsbo_sampler.sample_from_high_quality_regions(
                num_samples=num_prior_samples,
                exploration_noise=0.0  # No noise for visualization
            )
            latent_vectors_prior = prior_samples
    
    # ===== 3. Combine for joint dimensionality reduction =====
    print(f"    Combining posterior and prior...")
    all_latents = np.vstack([latent_vectors_posterior, latent_vectors_prior]) if len(latent_vectors_prior) > 0 else latent_vectors_posterior
    
    # Set high-quality plot parameters
    plt.rcParams['figure.dpi'] = 300
    plt.rcParams['savefig.dpi'] = 300
    
    # Create figure with 3 subplots
    fig = plt.figure(figsize=(24, 8))
    
    # ===== 4. t-SNE Visualization =====
    print(f"    Computing t-SNE projection...")
    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)
    all_latents_tsne = tsne.fit_transform(all_latents)
    
    # Split back into posterior and prior
    posterior_tsne = all_latents_tsne[:num_samples]
    prior_tsne = all_latents_tsne[num_samples:] if len(latent_vectors_prior) > 0 else np.array([])
    
    # Plot 1: AMP vs non-AMP separation (POSTERIOR only)
    ax1 = fig.add_subplot(1, 3, 1)
    
    # Separate AMP and non-AMP
    amp_mask = labels_posterior == 1
    non_amp_mask = labels_posterior == 0
    
    # Plot non-AMP (blue) and AMP (red)
    ax1.scatter(posterior_tsne[non_amp_mask, 0], posterior_tsne[non_amp_mask, 1],
               c='blue', label='Non-AMP', alpha=0.6, s=30, edgecolors='darkblue', linewidth=0.5, marker='o')
    ax1.scatter(posterior_tsne[amp_mask, 0], posterior_tsne[amp_mask, 1],
               c='red', label='AMP', alpha=0.6, s=30, edgecolors='darkred', linewidth=0.5, marker='o')
    
    ax1.set_xlabel('t-SNE Dimension 1', fontweight='bold', fontsize=12)
    ax1.set_ylabel('t-SNE Dimension 2', fontweight='bold', fontsize=12)
    ax1.set_title(f'âœ… AMP vs Non-AMP Separation (Posterior)\nEpoch {epoch}', fontsize=14, fontweight='bold')
    ax1.legend(loc='best', framealpha=0.9, fontsize=11)
    ax1.grid(True, alpha=0.3)
    
    # Add statistics
    amp_count = np.sum(amp_mask)
    non_amp_count = np.sum(non_amp_mask)
    ax1.text(0.02, 0.98, f'AMP: {amp_count} ({amp_count/num_samples*100:.1f}%)\nNon-AMP: {non_amp_count} ({non_amp_count/num_samples*100:.1f}%)',
            transform=ax1.transAxes, fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # Plot 2: Prior vs Posterior overlay
    ax2 = fig.add_subplot(1, 3, 2)
    
    # Plot posterior (circles, gray)
    ax2.scatter(posterior_tsne[:, 0], posterior_tsne[:, 1],
               c='gray', label='Posterior (Encoded)', alpha=0.4, s=20, marker='o', edgecolors='none')
    
    # Plot prior (triangles, green)
    if len(prior_tsne) > 0:
        ax2.scatter(prior_tsne[:, 0], prior_tsne[:, 1],
                   c='green', label='Prior (LSBO HQ)', alpha=0.7, s=50, marker='^', edgecolors='darkgreen', linewidth=0.8)
    
    ax2.set_xlabel('t-SNE Dimension 1', fontweight='bold', fontsize=12)
    ax2.set_ylabel('t-SNE Dimension 2', fontweight='bold', fontsize=12)
    ax2.set_title(f'âœ… Prior vs Posterior Matching\nEpoch {epoch}', fontsize=14, fontweight='bold')
    ax2.legend(loc='best', framealpha=0.9, fontsize=11)
    ax2.grid(True, alpha=0.3)
    
    # Add MMD loss info
    ax2.text(0.02, 0.98, f'Goal: Prior â‰ˆ Posterior\n(MMD Loss â†’ 0)',
            transform=ax2.transAxes, fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))
    
    # Plot 3: Quality score coloring (POSTERIOR only, colored by predicted quality)
    ax3 = fig.add_subplot(1, 3, 3)
    
    # Compute quality scores for posterior samples
    print(f"    Computing quality scores...")
    
    # Use distance from HQ mean as proxy for quality
    if lsbo_sampler is not None and hasattr(lsbo_sampler, 'high_quality_regions'):
        if len(lsbo_sampler.high_quality_regions) > 0:
            hq_latents = np.array([vec for vec, _ in lsbo_sampler.high_quality_regions])
            hq_mean = np.mean(hq_latents, axis=0)
            
            # Compute distance from HQ mean (inverse as proxy for quality)
            distances = np.linalg.norm(latent_vectors_posterior - hq_mean, axis=1)
            # Normalize to 0-1 range (closer = higher quality)
            quality_proxy = 1 - (distances - distances.min()) / (distances.max() - distances.min() + 1e-8)
            quality_proxy = 0.7 + 0.3 * quality_proxy  # Scale to 0.7-1.0 range
        else:
            quality_proxy = np.ones(num_samples) * 0.8
    else:
        quality_proxy = np.ones(num_samples) * 0.8
    
    # Plot with quality coloring
    scatter3 = ax3.scatter(posterior_tsne[:, 0], posterior_tsne[:, 1],
                          c=quality_proxy, cmap='viridis', alpha=0.7, s=30, 
                          edgecolors='black', linewidth=0.5, vmin=0.7, vmax=1.0)
    
    ax3.set_xlabel('t-SNE Dimension 1', fontweight='bold', fontsize=12)
    ax3.set_ylabel('t-SNE Dimension 2', fontweight='bold', fontsize=12)
    ax3.set_title(f'âœ… Quality Score Distribution\nEpoch {epoch}', fontsize=14, fontweight='bold')
    
    cbar3 = plt.colorbar(scatter3, ax=ax3)
    cbar3.set_label('Quality Score (Proxy)', fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # Add statistics
    high_quality_count = np.sum(quality_proxy > 0.85)
    ax3.text(0.02, 0.98, f'High Quality (>0.85): {high_quality_count}\n({high_quality_count/num_samples*100:.1f}%)',
            transform=ax3.transAxes, fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))
    
    # Add main title
    fig.suptitle(f'ðŸ§¬ LSBO-Guided Latent Space Analysis (t-SNE) - Epoch {epoch}', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    # Save figure
    output_path = Path(output_dir) / f'latent_space_epoch_{epoch:03d}.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"    âœ… Latent space visualization saved: {output_path}")
    
    return output_path


def visualize_high_quality_regions(lsbo_sampler, output_dir, epoch):
    """
    Visualize the distribution of high-quality latent regions.
    
    Args:
        lsbo_sampler: LSBO sampler with high-quality regions
        output_dir: Output directory for visualizations
        epoch: Current epoch number
    """
    if len(lsbo_sampler.high_quality_regions) == 0:
        return None
    
    # Extract latent vectors and scores
    latent_vectors = np.array([vec for vec, _ in lsbo_sampler.high_quality_regions])
    scores = np.array([score for _, score in lsbo_sampler.high_quality_regions])
    
    # Set high-quality plot parameters
    plt.rcParams['figure.dpi'] = 300
    plt.rcParams['savefig.dpi'] = 300
    
    # Create figure
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Score Distribution
    ax1 = axes[0, 0]
    ax1.hist(scores, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
    ax1.axvline(np.mean(scores), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(scores):.4f}')
    ax1.axvline(np.median(scores), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(scores):.4f}')
    ax1.set_xlabel('Quality Score', fontweight='bold')
    ax1.set_ylabel('Frequency', fontweight='bold')
    ax1.set_title('ðŸ“Š Quality Score Distribution', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. PCA of High-Quality Regions
    ax2 = axes[0, 1]
    pca = PCA(n_components=2)
    latent_pca = pca.fit_transform(latent_vectors)
    scatter = ax2.scatter(latent_pca[:, 0], latent_pca[:, 1], 
                         c=scores, cmap='viridis', alpha=0.6, s=30, edgecolors='black', linewidth=0.5)
    ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% var)', fontweight='bold')
    ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% var)', fontweight='bold')
    ax2.set_title('ðŸ—ºï¸ High-Quality Regions (PCA)', fontsize=14, fontweight='bold')
    cbar = plt.colorbar(scatter, ax=ax2)
    cbar.set_label('Quality Score', fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # 3. Score vs Latent Norm
    ax3 = axes[1, 0]
    norms = np.linalg.norm(latent_vectors, axis=1)
    ax3.scatter(norms, scores, alpha=0.5, s=20, edgecolors='black', linewidth=0.5)
    ax3.set_xlabel('Latent Vector Norm', fontweight='bold')
    ax3.set_ylabel('Quality Score', fontweight='bold')
    ax3.set_title('ðŸ“ˆ Score vs Latent Magnitude', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # 4. Statistics Summary
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    stats_text = f"""
    ðŸŽ¯ High-Quality Regions Statistics
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ðŸ“Š Region Count: {len(scores)}
    
    â­ Quality Scores:
       â€¢ Mean: {np.mean(scores):.4f}
       â€¢ Median: {np.median(scores):.4f}
       â€¢ Std Dev: {np.std(scores):.4f}
       â€¢ Min: {np.min(scores):.4f}
       â€¢ Max: {np.max(scores):.4f}
    
    ðŸ“ Latent Vector Norms:
       â€¢ Mean: {np.mean(norms):.4f}
       â€¢ Median: {np.median(norms):.4f}
       â€¢ Std Dev: {np.std(norms):.4f}
    
    ðŸŽ“ Quality Breakdown:
       â€¢ Excellent (â‰¥0.85): {np.sum(scores >= 0.85)}
       â€¢ Good (0.75-0.85): {np.sum((scores >= 0.75) & (scores < 0.85))}
       â€¢ Fair (0.70-0.75): {np.sum((scores >= 0.70) & (scores < 0.75))}
    
    âœ¨ LSBO-guided sampling ensures all
       regions are biologically relevant!
    """
    ax4.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',
            verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))
    
    # Add main title
    fig.suptitle(f'ðŸŽ¯ LSBO High-Quality Regions Analysis - Epoch {epoch}', 
                 fontsize=16, fontweight='bold', y=0.98)
    
    # Save figure
    output_path = Path(output_dir) / f'hq_regions_epoch_{epoch:03d}.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return output_path
